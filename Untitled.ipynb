{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc968fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import time\n",
    "import gym\n",
    "import random\n",
    "from keras import Sequential\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.activations import relu, linear\n",
    "\n",
    "\n",
    "class DeepQNetwork:\n",
    "\n",
    "\n",
    "    def __init__(self, action_space, state_space, learning_rate=0.001):\n",
    "        # initialize Deep Q-Network parameters\n",
    "        self.epsilon = 1.0\n",
    "        self.gamma = .95\n",
    "        self.batch_size = 64\n",
    "        self.epsilon_min = .01\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon_decay = .90\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.action_space_size = action_space\n",
    "        self.state_space_shape = state_space\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # build the neural network model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, input_dim=self.state_space_shape, activation=relu))\n",
    "        model.add(Dense(25, activation=relu))\n",
    "        model.add(Dense(self.action_space_size, activation=linear))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def rememberFunction(self, state, action, reward, nextState, done):\n",
    "        # remember the experience (state, action, reward, next_state, done)\n",
    "        self.memory.append((state, action, reward, nextState, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        # choose an action based on epsilon-greedy policy\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_space_size)\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        actValues = self.model.predict(state)\n",
    "        return np.argmax(actValues[0])\n",
    "\n",
    "    def replayFunction(self):\n",
    "        # experience replay to train the model\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        miniBatchVar = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([i[0] for i in miniBatchVar])\n",
    "        actions = np.array([i[1] for i in miniBatchVar])\n",
    "        rewards = np.array([i[2] for i in miniBatchVar])\n",
    "        nextStates = np.array([i[3] for i in miniBatchVar])\n",
    "        dones = np.array([i[4] for i in miniBatchVar])\n",
    "\n",
    "        states = np.squeeze(states)\n",
    "        nextStates = np.squeeze(nextStates)\n",
    "\n",
    "        targets = rewards + self.gamma * (np.amax(self.model.predict_on_batch(nextStates), axis=1)) * (1 - dones)\n",
    "        targetsFull = self.model.predict_on_batch(states)\n",
    "\n",
    "        indexes = np.array([i for i in range(self.batch_size)])\n",
    "        targetsFull[[indexes], [actions]] = targets\n",
    "\n",
    "        self.model.fit(states, targetsFull, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "def rewardFunction(nextStateInfo):\n",
    "    # define the reward function based on the next state\n",
    "    nextState = nextStateInfo[0]  # extracting the nextState array\n",
    "    if nextState[0] >= 0.5:\n",
    "        print(\"Car reached the top\")\n",
    "        return 10\n",
    "    if nextState[0] > -0.4:\n",
    "        return (1 + nextState[0]) ** 2\n",
    "    return 0\n",
    "\n",
    "\n",
    "def trainDQNetwork(environment, agent, episode):\n",
    "    # Training the Deep Q-Network\n",
    "    episodeScores = []\n",
    "    for e in range(episode):\n",
    "        state = environment.reset()[0]  # extracting the state array\n",
    "        score = 0\n",
    "        maxSteps = 1000\n",
    "        for i in range(maxSteps):\n",
    "            environment.render()\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    quit()\n",
    "            state = np.array(state)  \n",
    "            action = agent.act(state)\n",
    "            stepResult = environment.step(action)  # get all return values\n",
    "            nextState, reward, done = stepResult[:3]  # get the first three elements\n",
    "            reward = rewardFunction(stepResult)  # pass values to rewardFunction function\n",
    "            score += reward\n",
    "            nextState = np.array(nextState)  \n",
    "            agent.rememberFunction(state, action, reward, nextState, done)\n",
    "            state = nextState\n",
    "            agent.replayFunction()\n",
    "            if done:\n",
    "                print(\"Episode: {}/{}, score: {}\".format(e, episode, score))\n",
    "                break\n",
    "        episodeScores.append(score)\n",
    "    return episodeScores\n",
    "\n",
    "def main():\n",
    "    pygame.init()  # initialize Pygame\n",
    "    environment = gym.make('MountainCar-v0', render_mode=\"human\") # render as human\n",
    "    np.random.seed(10)  # numpy random seed\n",
    "\n",
    "    print(environment.observation_space)\n",
    "    print(environment.action_space)\n",
    "    agent = DeepQNetwork(environment.action_space.n, environment.observation_space.shape[0], learning_rate=0.001)\n",
    "    episodes = 60\n",
    "    episodeScores = trainDQNetwork(environment, agent, episodes)\n",
    "    plt.plot([i+1 for i in range(episodes)], episodeScores)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

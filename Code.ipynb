{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9450964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid more than 1 element per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "\n",
    "class WarehouseEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Environment representing a warehouse where a robot navigates to pick up packages and deliver them to designated points.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_size, num_packages, num_delivery_points):\n",
    "        \"\"\"\n",
    "        Initializes the Warehouse environment.\n",
    "\n",
    "        Parameters:\n",
    "        - grid_size (int): Size of the grid layout.\n",
    "        - num_packages (int): Number of packages in the warehouse.\n",
    "        - num_delivery_points (int): Number of delivery points in the warehouse.\n",
    "        \"\"\"\n",
    "        super(WarehouseEnv, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_packages = num_packages\n",
    "        self.num_delivery_points = num_delivery_points\n",
    "        self.action_space = spaces.Discrete(6)  # Up, Down, Left, Right, Pick up, Drop off\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(grid_size),  # Robot X position\n",
    "            spaces.Discrete(grid_size),  # Robot Y position\n",
    "            spaces.MultiBinary(num_packages),  # Package locations\n",
    "            spaces.MultiBinary(num_delivery_points),  # Delivery locations\n",
    "            spaces.MultiBinary(num_packages)  # Inventory\n",
    "        ))\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to its initial state.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Initial observation of the environment.\n",
    "        \"\"\"\n",
    "        self.robot_pos = [0, 0]\n",
    "        self.packages = np.zeros(self.grid_size)\n",
    "        self.delivery_points = np.zeros(self.grid_size)\n",
    "        self.inventory = np.zeros(self.num_packages)\n",
    "\n",
    "        # Randomly place at least one package without overlapping with delivery points\n",
    "        placed_package = False\n",
    "        while not placed_package:\n",
    "            rand_x = np.random.randint(self.grid_size)\n",
    "            rand_y = np.random.randint(self.grid_size)\n",
    "            while self.delivery_points[rand_x] == 1:\n",
    "                rand_x = np.random.randint(self.grid_size)\n",
    "                rand_y = np.random.randint(self.grid_size)\n",
    "            self.packages[rand_x] = 1\n",
    "            placed_package = True\n",
    "\n",
    "        # Ensure delivery points are placed without overlapping with packages\n",
    "        placed_delivery = 0\n",
    "        while placed_delivery < self.num_delivery_points:\n",
    "            rand_x = np.random.randint(self.grid_size)\n",
    "            if self.delivery_points[rand_x] == 0 and self.packages[rand_x] == 0:\n",
    "                self.delivery_points[rand_x] = 1\n",
    "                placed_delivery += 1\n",
    "\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Executes one time step in the environment.\n",
    "\n",
    "        Parameters:\n",
    "        - action (int): Action to be taken by the agent.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): New observation of the environment.\n",
    "        - reward (float): Reward received from the environment.\n",
    "        - done (bool): Whether the episode is done or not.\n",
    "        - info (dict): Additional information about the environment.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        done = False\n",
    "        new_pos = self.robot_pos[:]\n",
    "\n",
    "        if action == 0:  # Move Up\n",
    "            new_pos[0] -= 1\n",
    "        elif action == 1:  # Move Down\n",
    "            new_pos[0] += 1\n",
    "        elif action == 2:  # Move Left\n",
    "            new_pos[1] -= 1\n",
    "        elif action == 3:  # Move Right\n",
    "            new_pos[1] += 1\n",
    "        elif action == 4:  # Pick up\n",
    "            if tuple(self.robot_pos) in self.packages:\n",
    "                package_index = list(self.robot_pos).index(1)\n",
    "                self.inventory[package_index] = 1\n",
    "                self.packages[package_index] = 0\n",
    "                reward += 10\n",
    "            else:\n",
    "                reward -= 1\n",
    "        elif action == 5:  # Drop off\n",
    "            if tuple(self.robot_pos) in self.delivery_points:\n",
    "                if 1 in self.inventory:\n",
    "                    package_index = list(self.inventory).index(1)\n",
    "                    self.inventory[package_index] = 0\n",
    "                    reward += 100\n",
    "                    # Check if all packages have been delivered\n",
    "                    if np.sum(self.inventory) == 0:\n",
    "                        done = True  # Episode ends if all packages are delivered\n",
    "                else:\n",
    "                    reward -= 10\n",
    "            else:\n",
    "                reward -= 10\n",
    "\n",
    "        if 0 <= new_pos[0] < self.grid_size and 0 <= new_pos[1] < self.grid_size:\n",
    "            self.robot_pos = new_pos  # Update the robot's position\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, done, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Returns the current observation of the environment.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Current observation of the environment.\n",
    "        \"\"\"\n",
    "        return tuple(self.robot_pos + [int(x) for x in self.packages] + [int(x) for x in self.delivery_points] + [int(x) for x in self.inventory])\n",
    "\n",
    "def draw_env(screen, env):\n",
    "    \"\"\"\n",
    "    Draws the current state of the environment on the screen.\n",
    "\n",
    "    Parameters:\n",
    "    - screen (pygame.Surface): Pygame surface representing the screen.\n",
    "    - env (WarehouseEnv): Instance of the Warehouse environment.\n",
    "    \"\"\"\n",
    "    screen.fill((255, 255, 255))\n",
    "    cell_size = 50\n",
    "    grid_size = env.grid_size\n",
    "    robot_img = pygame.image.load(\"robot.png\").convert_alpha()\n",
    "    package_img = pygame.image.load(\"package.png\").convert_alpha()\n",
    "    delivery_img = pygame.image.load(\"delivery.png\").convert_alpha()\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        pygame.draw.line(screen, (0, 0, 0), (i * cell_size, 0), (i * cell_size, grid_size * cell_size))\n",
    "        pygame.draw.line(screen, (0, 0, 0), (0, i * cell_size), (grid_size * cell_size, i * cell_size))\n",
    "\n",
    "    robot_pos = env.robot_pos\n",
    "    screen.blit(robot_img, (robot_pos[1] * cell_size, robot_pos[0] * cell_size))\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if env.packages[i] == 1:\n",
    "                screen.blit(package_img, (j * cell_size, i * cell_size))\n",
    "            if env.delivery_points[i] == 1:\n",
    "                screen.blit(delivery_img, (j * cell_size, i * cell_size))\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Q-learning parameters\n",
    "gamma = 0.9\n",
    "alpha = 0.1\n",
    "\n",
    "def q_learning(env, num_episodes=1000, max_steps_per_episode=3):\n",
    "    \"\"\"\n",
    "    Performs Q-learning to train the agent.\n",
    "\n",
    "    Parameters:\n",
    "    - env (WarehouseEnv): Instance of the Warehouse environment.\n",
    "    - num_episodes (int): Number of episodes for training.\n",
    "    - max_steps_per_episode (int): Maximum number of steps per episode.\n",
    "    \"\"\"\n",
    "    q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "        while not done and steps < max_steps_per_episode:\n",
    "            action = np.argmax(q_table[state])\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            q_value = q_table[state, action]\n",
    "            max_next_q_value = np.max(q_table[next_state])\n",
    "            new_q_value = q_value + alpha * (reward + gamma * max_next_q_value - q_value)\n",
    "            q_table[state, action] = new_q_value\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "        print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "def main():\n",
    "    env = WarehouseEnv(grid_size=5, num_packages=3, num_delivery_points=2)\n",
    "\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((env.grid_size * 50, env.grid_size * 50))\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    num_episodes = 1000\n",
    "    max_steps_per_episode = 100  # Define maximum steps per episode\n",
    "    for episode in range(num_episodes):\n",
    "        print(f\"Current Episode: {episode+1}\")  # Print current episode\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        steps = 0  # Initialize step count\n",
    "        exit_flag = False  # Flag to exit event handling loop\n",
    "        while not done and steps < max_steps_per_episode:  # Check maximum steps condition\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    exit_flag = True  # Set the exit flag to True\n",
    "                    break  # Exit the event handling loop\n",
    "            if exit_flag:\n",
    "                break  # Exit the episode loop if the exit flag is True\n",
    "            draw_env(screen, env)\n",
    "            action = env.action_space.sample()\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            clock.tick(10)\n",
    "            steps += 1  # Increment step count\n",
    "        print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "\n",
    "class WarehouseEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Environment representing a warehouse where a robot navigates to pick up packages and deliver them to designated points.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_size, num_packages, num_delivery_points):\n",
    "        \"\"\"\n",
    "        Initializes the Warehouse environment.\n",
    "\n",
    "        Parameters:\n",
    "        - grid_size (int): Size of the grid layout.\n",
    "        - num_packages (int): Number of packages in the warehouse.\n",
    "        - num_delivery_points (int): Number of delivery points in the warehouse.\n",
    "        \"\"\"\n",
    "        super(WarehouseEnv, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_packages = num_packages\n",
    "        self.num_delivery_points = num_delivery_points\n",
    "        self.action_space = spaces.Discrete(6)  # Up, Down, Left, Right, Pick up, Drop off\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(grid_size),  # Robot X position\n",
    "            spaces.Discrete(grid_size),  # Robot Y position\n",
    "            spaces.MultiBinary(num_packages),  # Package locations\n",
    "            spaces.MultiBinary(num_delivery_points),  # Delivery locations\n",
    "            spaces.MultiBinary(num_packages)  # Inventory\n",
    "        ))\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to its initial state.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Initial observation of the environment.\n",
    "        \"\"\"\n",
    "        self.robot_pos = [0, 0]\n",
    "        self.packages = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.delivery_points = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.inventory = np.zeros(self.num_packages)\n",
    "        self.package_to_delivery = {}  # Dictionary to store package to delivery point associations\n",
    "\n",
    "        # Randomly place delivery points\n",
    "        for _ in range(self.num_delivery_points):\n",
    "            rand_x = np.random.randint(self.grid_size)\n",
    "            rand_y = np.random.randint(self.grid_size)\n",
    "            while self.delivery_points[rand_x][rand_y] == 1:  # Ensure unique location for each delivery point\n",
    "                rand_x = np.random.randint(self.grid_size)\n",
    "                rand_y = np.random.randint(self.grid_size)\n",
    "            self.delivery_points[rand_x][rand_y] = 1\n",
    "\n",
    "        # Assign packages to remaining empty locations\n",
    "        placed_packages = 0\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if placed_packages < self.num_packages and self.delivery_points[i][j] == 0:\n",
    "                    self.packages[i][j] = 1\n",
    "                    # Find the nearest delivery point and associate the package with it\n",
    "                    dist_to_delivery = np.inf\n",
    "                    nearest_delivery = None\n",
    "                    for di in range(self.grid_size):\n",
    "                        for dj in range(self.grid_size):\n",
    "                            if self.delivery_points[di][dj] == 1:\n",
    "                                dist = abs(i - di) + abs(j - dj)\n",
    "                                if dist < dist_to_delivery:\n",
    "                                    dist_to_delivery = dist\n",
    "                                    nearest_delivery = (di, dj)\n",
    "                    self.package_to_delivery[(i, j)] = nearest_delivery\n",
    "                    placed_packages += 1\n",
    "\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Executes one time step in the environment.\n",
    "\n",
    "        Parameters:\n",
    "        - action (int): Action to be taken by the agent.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): New observation of the environment.\n",
    "        - reward (float): Reward received from the environment.\n",
    "        - done (bool): Whether the episode is done or not.\n",
    "        - info (dict): Additional information about the environment.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        done = False\n",
    "        new_pos = self.robot_pos[:]\n",
    "\n",
    "        if action == 0:  # Move Up\n",
    "            new_pos[0] -= 1\n",
    "        elif action == 1:  # Move Down\n",
    "            new_pos[0] += 1\n",
    "        elif action == 2:  # Move Left\n",
    "            new_pos[1] -= 1\n",
    "        elif action == 3:  # Move Right\n",
    "            new_pos[1] += 1\n",
    "        elif action == 4:  # Pick up\n",
    "            if tuple(self.robot_pos) in self.packages:\n",
    "                package_index = list(self.robot_pos).index(1)\n",
    "                self.inventory[package_index] = 1\n",
    "                self.packages[self.robot_pos[0]][self.robot_pos[1]] = 0\n",
    "                reward += 10  # Add a positive reward for picking up a package\n",
    "            else:\n",
    "                reward -= 1\n",
    "        elif action == 5:  # Drop off\n",
    "            if tuple(self.robot_pos) in self.delivery_points:\n",
    "                if 1 in self.inventory:\n",
    "                    package_index = list(self.inventory).index(1)\n",
    "                    self.inventory[package_index] = 0\n",
    "                    reward += 100\n",
    "                    # Check if all packages have been delivered\n",
    "                    if np.sum(self.inventory) == 0:\n",
    "                        done = True  # Episode ends if all packages are delivered\n",
    "                else:\n",
    "                    reward -= 10\n",
    "            else:\n",
    "                reward -= 10\n",
    "\n",
    "        # Positive reward for reaching intermediate steps (packages or delivery points)\n",
    "        if reward == 0:\n",
    "            reward += 1\n",
    "\n",
    "        if 0 <= new_pos[0] < self.grid_size and 0 <= new_pos[1] < self.grid_size:\n",
    "            self.robot_pos = new_pos  # Update the robot's position\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, done, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Returns the current observation of the environment.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Current observation of the environment.\n",
    "        \"\"\"\n",
    "        package_locations = [int(x) for row in self.packages for x in row]\n",
    "        delivery_locations = [int(x) for row in self.delivery_points for x in row]\n",
    "        inventory = [int(x) for x in self.inventory]\n",
    "        return tuple(self.robot_pos + package_locations + delivery_locations + inventory)\n",
    "\n",
    "def draw_env(screen, env):\n",
    "    \"\"\"\n",
    "    Draws the current state of the environment on the screen.\n",
    "\n",
    "    Parameters:\n",
    "    - screen (pygame.Surface): Pygame surface representing the screen.\n",
    "    - env (WarehouseEnv): Instance of the Warehouse environment.\n",
    "    \"\"\"\n",
    "    screen.fill((255, 255, 255))\n",
    "    cell_size = 50\n",
    "    grid_size = env.grid_size\n",
    "    robot_img = pygame.image.load(\"robot.png\").convert_alpha()\n",
    "    package_img = pygame.image.load(\"package.png\").convert_alpha()\n",
    "    delivery_img = pygame.image.load(\"delivery.png\").convert_alpha()\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            pygame.draw.rect(screen, (255, 255, 255), (j * cell_size, i * cell_size, cell_size, cell_size))\n",
    "            pygame.draw.rect(screen, (0, 0, 0), (j * cell_size, i * cell_size, cell_size, cell_size), 1)\n",
    "\n",
    "            if env.packages[i][j] == 1:\n",
    "                screen.blit(package_img, (j * cell_size, i * cell_size))\n",
    "            if env.delivery_points[i][j] == 1:\n",
    "                screen.blit(delivery_img, (j * cell_size, i * cell_size))\n",
    "\n",
    "    robot_pos = env.robot_pos\n",
    "    screen.blit(robot_img, (robot_pos[1] * cell_size, robot_pos[0] * cell_size))\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = WarehouseEnv(grid_size=5, num_packages=3, num_delivery_points=3)\n",
    "\n",
    "    # Print the number of delivery points and packages\n",
    "    print(f\"Number of delivery points: {env.num_delivery_points}\")\n",
    "    print(f\"Number of packages: {env.num_packages}\")\n",
    "\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((env.grid_size * 50, env.grid_size * 50))\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    num_episodes = 1000\n",
    "    max_steps_per_episode = 1000  # Define maximum steps per episode\n",
    "    epsilon = 0.1  # Define epsilon value for epsilon-greedy strategy\n",
    "    for episode in range(num_episodes):\n",
    "        print(f\"Current Episode: {episode+1}\")  # Print current episode\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        steps = 0  # Initialize step count\n",
    "        exit_flag = False  # Flag to exit event handling loop\n",
    "        while not done and steps < max_steps_per_episode:  # Check maximum steps condition\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    exit_flag = True  # Set the exit flag to True\n",
    "                    break  # Exit the event handling loop\n",
    "            if exit_flag:\n",
    "                break  # Exit the episode loop if the exit flag is True\n",
    "            draw_env(screen, env)\n",
    "\n",
    "            # Epsilon-greedy action selection\n",
    "            if random.random() < epsilon:\n",
    "                action = env.action_space.sample()  # Choose a random action\n",
    "            else:\n",
    "                # Choose the greedy action based on Q-values (not implemented in this code)\n",
    "                action = 0  # Replace this with your Q-learning or DQN action selection logic\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            clock.tick(10)\n",
    "            steps += 1  # Increment step count\n",
    "        print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "\n",
    "class WarehouseEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Environment representing a warehouse where a robot navigates to pick up packages and deliver them to designated points.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_size, num_packages, num_delivery_points):\n",
    "        \"\"\"\n",
    "        Initializes the Warehouse environment.\n",
    "\n",
    "        Parameters:\n",
    "        - grid_size (int): Size of the grid layout.\n",
    "        - num_packages (int): Number of packages in the warehouse.\n",
    "        - num_delivery_points (int): Number of delivery points in the warehouse.\n",
    "        \"\"\"\n",
    "        super(WarehouseEnv, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_packages = num_packages\n",
    "        self.num_delivery_points = num_delivery_points\n",
    "        self.action_space = spaces.Discrete(6)  # Up, Down, Left, Right, Pick up, Drop off\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(grid_size),  # Robot X position\n",
    "            spaces.Discrete(grid_size),  # Robot Y position\n",
    "            spaces.MultiBinary(num_packages),  # Package locations\n",
    "            spaces.MultiBinary(num_delivery_points),  # Delivery locations\n",
    "            spaces.MultiBinary(num_packages)  # Inventory\n",
    "        ))\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to its initial state.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Initial observation of the environment.\n",
    "        \"\"\"\n",
    "        self.robot_pos = [0, 0]\n",
    "        self.packages = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.delivery_points = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.inventory = np.zeros(self.num_packages)\n",
    "        self.package_to_delivery = {}  # Dictionary to store package to delivery point associations\n",
    "\n",
    "        # Randomly place delivery points\n",
    "        for _ in range(self.num_delivery_points):\n",
    "            rand_x = np.random.randint(self.grid_size)\n",
    "            rand_y = np.random.randint(self.grid_size)\n",
    "            while self.delivery_points[rand_x][rand_y] == 1:  # Ensure unique location for each delivery point\n",
    "                rand_x = np.random.randint(self.grid_size)\n",
    "                rand_y = np.random.randint(self.grid_size)\n",
    "            self.delivery_points[rand_x][rand_y] = 1\n",
    "\n",
    "        # Assign packages to remaining empty locations\n",
    "        placed_packages = 0\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if placed_packages < self.num_packages and self.delivery_points[i][j] == 0:\n",
    "                    self.packages[i][j] = 1\n",
    "                    # Find the nearest delivery point and associate the package with it\n",
    "                    dist_to_delivery = np.inf\n",
    "                    nearest_delivery = None\n",
    "                    for di in range(self.grid_size):\n",
    "                        for dj in range(self.grid_size):\n",
    "                            if self.delivery_points[di][dj] == 1:\n",
    "                                dist = abs(i - di) + abs(j - dj)\n",
    "                                if dist < dist_to_delivery:\n",
    "                                    dist_to_delivery = dist\n",
    "                                    nearest_delivery = (di, dj)\n",
    "                    self.package_to_delivery[(i, j)] = nearest_delivery\n",
    "                    placed_packages += 1\n",
    "\n",
    "        self.q_table = np.zeros((2 ** (self.grid_size * 2 + self.num_packages * 2), self.action_space.n))\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Executes one time step in the environment.\n",
    "\n",
    "        Parameters:\n",
    "        - action (int): Action to be taken by the agent.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): New observation of the environment.\n",
    "        - reward (float): Reward received from the environment.\n",
    "        - done (bool): Whether the episode is done or not.\n",
    "        - info (dict): Additional information about the environment.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        done = False\n",
    "        new_pos = self.robot_pos[:]\n",
    "\n",
    "        if action == 0:  # Move Up\n",
    "            new_pos[0] -= 1\n",
    "        elif action == 1:  # Move Down\n",
    "            new_pos[0] += 1\n",
    "        elif action == 2:  # Move Left\n",
    "            new_pos[1] -= 1\n",
    "        elif action == 3:  # Move Right\n",
    "            new_pos[1] += 1\n",
    "        elif action == 4:  # Pick up\n",
    "            if tuple(self.robot_pos) in self.packages:\n",
    "                package_index = list(self.robot_pos).index(1)\n",
    "                self.inventory[package_index] = 1\n",
    "                self.packages[self.robot_pos[0]][self.robot_pos[1]] = 0\n",
    "                reward += 10  # Add a positive reward for picking up a package\n",
    "            else:\n",
    "                reward -= 1\n",
    "        elif action == 5:  # Drop off\n",
    "            if tuple(self.robot_pos) in self.delivery_points:\n",
    "                if 1 in self.inventory:\n",
    "                    package_index = list(self.inventory).index(1)\n",
    "                    self.inventory[package_index] = 0\n",
    "                    reward += 100\n",
    "                    # Check if all packages have been delivered\n",
    "                    if np.sum(self.inventory) == 0:\n",
    "                        done = True  # Episode ends if all packages are delivered\n",
    "                else:\n",
    "                    reward -= 10\n",
    "            else:\n",
    "                reward -= 10\n",
    "\n",
    "        # Positive reward for reaching intermediate steps (packages or delivery points)\n",
    "        if reward == 0:\n",
    "            reward += 1\n",
    "\n",
    "        if 0 <= new_pos[0] < self.grid_size and 0 <= new_pos[1] < self.grid_size:\n",
    "            self.robot_pos = new_pos  # Update the robot's position\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, done, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Returns the current observation of the environment.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Current observation of the environment.\n",
    "        \"\"\"\n",
    "        package_locations = [int(x) for row in self.packages for x in row]\n",
    "        delivery_locations = [int(x) for row in self.delivery_points for x in row]\n",
    "        inventory = [int(x) for x in self.inventory]\n",
    "        return tuple(self.robot_pos + package_locations + delivery_locations + inventory)\n",
    "\n",
    "def hash_state(env, state):\n",
    "    \"\"\"\n",
    "    Hashes the state tuple into a single integer for indexing.\n",
    "\n",
    "    Parameters:\n",
    "    - env (WarehouseEnv): Instance of the Warehouse environment.\n",
    "    - state (tuple): State tuple to be hashed.\n",
    "\n",
    "    Returns:\n",
    "    - hash_value (int): Hashed value of the state.\n",
    "    \"\"\"\n",
    "    hash_value = 0\n",
    "    for i, s in enumerate(state):\n",
    "        hash_value += s * (2 ** i)\n",
    "    return hash_value % env.q_table.shape[0]  # Ensure the hash value is within Q-table bounds\n",
    "\n",
    "\n",
    "def draw_env(screen, env):\n",
    "    \"\"\"\n",
    "    Draws the current state of the environment on the screen.\n",
    "\n",
    "    Parameters:\n",
    "    - screen (pygame.Surface): Pygame surface representing the screen.\n",
    "    - env (WarehouseEnv): Instance of the Warehouse environment.\n",
    "    \"\"\"\n",
    "    screen.fill((255, 255, 255))\n",
    "    cell_size = 50\n",
    "    grid_size = env.grid_size\n",
    "    robot_img = pygame.image.load(\"robot.png\").convert_alpha()\n",
    "    package_img = pygame.image.load(\"package.png\").convert_alpha()\n",
    "    delivery_img = pygame.image.load(\"delivery.png\").convert_alpha()\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            pygame.draw.rect(screen, (255, 255, 255), (j * cell_size, i * cell_size, cell_size, cell_size))\n",
    "            pygame.draw.rect(screen, (0, 0, 0), (j * cell_size, i * cell_size, cell_size, cell_size), 1)\n",
    "\n",
    "            if env.packages[i][j] == 1:\n",
    "                screen.blit(package_img, (j * cell_size, i * cell_size))\n",
    "            if env.delivery_points[i][j] == 1:\n",
    "                screen.blit(delivery_img, (j * cell_size, i * cell_size))\n",
    "\n",
    "    robot_pos = env.robot_pos\n",
    "    screen.blit(robot_img, (robot_pos[1] * cell_size, robot_pos[0] * cell_size))\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = WarehouseEnv(grid_size=5, num_packages=3, num_delivery_points=3)\n",
    "\n",
    "    # Print the number of delivery points and packages\n",
    "    print(f\"Number of delivery points: {env.num_delivery_points}\")\n",
    "    print(f\"Number of packages: {env.num_packages}\")\n",
    "\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((env.grid_size * 50, env.grid_size * 50))\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    num_episodes = 500\n",
    "    max_steps_per_episode = 1000  # Define maximum steps per episode\n",
    "    epsilon = 0.1  # Define epsilon value for epsilon-greedy strategy\n",
    "    learning_rate = 0.1  # Define the learning rate\n",
    "    discount_factor = 0.99  # Define the discount factor\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        print(f\"Current Episode: {episode+1}\")  # Print current episode\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        steps = 0  # Initialize step count\n",
    "        exit_flag = False  # Flag to exit event handling loop\n",
    "        while not done and steps < max_steps_per_episode:  # Check maximum steps condition\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    exit_flag = True  # Set the exit flag to True\n",
    "                    break  # Exit the event handling loop\n",
    "            if exit_flag:\n",
    "                break  # Exit the episode loop if the exit flag is True\n",
    "            draw_env(screen, env)\n",
    "\n",
    "            current_state = env._get_observation()\n",
    "            hashed_state = hash_state(env, current_state)\n",
    "            if random.random() < epsilon:\n",
    "                action = env.action_space.sample()  # Choose a random action\n",
    "            else:\n",
    "                action = np.argmax(env.q_table[hashed_state])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            next_hashed_state = hash_state(env, next_state)\n",
    "            best_next_action = np.argmax(env.q_table[next_hashed_state])\n",
    "\n",
    "            # Update Q-table\n",
    "            env.q_table[hashed_state][action] += learning_rate * (\n",
    "                reward + discount_factor * env.q_table[next_hashed_state][best_next_action] - env.q_table[hashed_state][action])\n",
    "\n",
    "            clock.tick(10)\n",
    "            steps += 1  # Increment step count\n",
    "        print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854dfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of delivery points: 3\n",
      "Number of packages: 3\n",
      "Current Episode: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/139b9d_s3s5bwn22mvsl_89m0000gn/T/ipykernel_54125/44413213.py:119: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if tuple(self.robot_pos) in self.packages:\n",
      "/var/folders/nn/139b9d_s3s5bwn22mvsl_89m0000gn/T/ipykernel_54125/44413213.py:127: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if tuple(self.robot_pos) in self.delivery_points:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Total Reward: 241\n",
      "Current Episode: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "\n",
    "class WarehouseEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Environment representing a warehouse where a robot navigates to pick up packages and deliver them to designated points.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_size, num_packages, num_delivery_points):\n",
    "        \"\"\"\n",
    "        Initializes the Warehouse environment.\n",
    "\n",
    "        Parameters:\n",
    "        - grid_size (int): Size of the grid layout.\n",
    "        - num_packages (int): Number of packages in the warehouse.\n",
    "        - num_delivery_points (int): Number of delivery points in the warehouse.\n",
    "        \"\"\"\n",
    "        super(WarehouseEnv, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_packages = num_packages\n",
    "        self.num_delivery_points = num_delivery_points\n",
    "        self.action_space = spaces.Discrete(6)  # Up, Down, Left, Right, Pick up, Drop off\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(grid_size),  # Robot X position\n",
    "            spaces.Discrete(grid_size),  # Robot Y position\n",
    "            spaces.MultiBinary(num_packages),  # Package locations\n",
    "            spaces.MultiBinary(num_delivery_points),  # Delivery locations\n",
    "            spaces.MultiBinary(num_packages)  # Inventory\n",
    "        ))\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to its initial state.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Initial observation of the environment.\n",
    "        \"\"\"\n",
    "        self.robot_pos = [0, 0]\n",
    "        self.packages = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.delivery_points = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.obstacles = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.inventory = np.zeros(self.num_packages)\n",
    "        self.package_to_delivery = {}  # Dictionary to store package to delivery point associations\n",
    "\n",
    "        # Randomly place delivery points\n",
    "        for _ in range(self.num_delivery_points):\n",
    "            rand_x = np.random.randint(self.grid_size)\n",
    "            rand_y = np.random.randint(self.grid_size)\n",
    "            while self.delivery_points[rand_x][rand_y] == 1:  # Ensure unique location for each delivery point\n",
    "                rand_x = np.random.randint(self.grid_size)\n",
    "                rand_y = np.random.randint(self.grid_size)\n",
    "            self.delivery_points[rand_x][rand_y] = 1\n",
    "\n",
    "        # Assign packages to remaining empty locations\n",
    "        placed_packages = 0\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if placed_packages < self.num_packages and self.delivery_points[i][j] == 0:\n",
    "                    self.packages[i][j] = 1\n",
    "                    # Find the nearest delivery point and associate the package with it\n",
    "                    dist_to_delivery = np.inf\n",
    "                    nearest_delivery = None\n",
    "                    for di in range(self.grid_size):\n",
    "                        for dj in range(self.grid_size):\n",
    "                            if self.delivery_points[di][dj] == 1:\n",
    "                                dist = abs(i - di) + abs(j - dj)\n",
    "                                if dist < dist_to_delivery:\n",
    "                                    dist_to_delivery = dist\n",
    "                                    nearest_delivery = (di, dj)\n",
    "                    self.package_to_delivery[(i, j)] = nearest_delivery\n",
    "                    placed_packages += 1\n",
    "\n",
    "        # Randomly place obstacles\n",
    "        num_obstacles = 0\n",
    "        while num_obstacles < 2:  # Add 2 obstacles per episode\n",
    "            rand_x = np.random.randint(self.grid_size)\n",
    "            rand_y = np.random.randint(self.grid_size)\n",
    "            if (\n",
    "                self.packages[rand_x][rand_y] == 0\n",
    "                and self.delivery_points[rand_x][rand_y] == 0\n",
    "                and self.obstacles[rand_x][rand_y] == 0\n",
    "            ):\n",
    "                self.obstacles[rand_x][rand_y] = 1\n",
    "                num_obstacles += 1\n",
    "\n",
    "        self.q_table = np.zeros((2 ** (self.grid_size * 2 + self.num_packages * 2), self.action_space.n))\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Executes one time step in the environment.\n",
    "\n",
    "        Parameters:\n",
    "        - action (int): Action to be taken by the agent.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): New observation of the environment.\n",
    "        - reward (float): Reward received from the environment.\n",
    "        - done (bool): Whether the episode is done or not.\n",
    "        - info (dict): Additional information about the environment.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        done = False\n",
    "        new_pos = self.robot_pos[:]\n",
    "\n",
    "        if action == 0:  # Move Up\n",
    "            new_pos[0] -= 1\n",
    "        elif action == 1:  # Move Down\n",
    "            new_pos[0] += 1\n",
    "        elif action == 2:  # Move Left\n",
    "            new_pos[1] -= 1\n",
    "        elif action == 3:  # Move Right\n",
    "            new_pos[1] += 1\n",
    "        elif action == 4:  # Pick up\n",
    "            if tuple(self.robot_pos) in self.packages:\n",
    "                package_index = list(self.robot_pos).index(1)\n",
    "                self.inventory[package_index] = 1\n",
    "                self.packages[self.robot_pos[0]][self.robot_pos[1]] = 0\n",
    "                reward += 10  # Add a positive reward for picking up a package\n",
    "            else:\n",
    "                reward -= 1\n",
    "        elif action == 5:  # Drop off\n",
    "            if tuple(self.robot_pos) in self.delivery_points:\n",
    "                if 1 in self.inventory:\n",
    "                    package_index = list(self.inventory).index(1)\n",
    "                    self.inventory[package_index] = 0\n",
    "                    reward += 100\n",
    "                    # Check if all packages have been delivered\n",
    "                    if np.sum(self.inventory) == 0:\n",
    "                        done = True  # Episode ends if all packages are delivered\n",
    "                else:\n",
    "                    reward -= 10\n",
    "            else:\n",
    "                reward -= 10\n",
    "\n",
    "        # Check if new position is within grid boundaries\n",
    "        if 0 <= new_pos[0] < self.grid_size and 0 <= new_pos[1] < self.grid_size:\n",
    "            # Check for collision with obstacles\n",
    "            if self.obstacles[new_pos[0]][new_pos[1]] == 1:\n",
    "                reward -= 5  # Negative reward for collision with obstacles\n",
    "                done = True  # Episode ends if collision occurs\n",
    "            else:\n",
    "                # Update robot's position\n",
    "                self.robot_pos = new_pos\n",
    "\n",
    "        # Positive reward for reaching intermediate steps (packages or delivery points)\n",
    "        if reward == 0:\n",
    "            reward += 1\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, done, {}\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Returns the current observation of the environment.\n",
    "\n",
    "        Returns:\n",
    "        - observation (tuple): Current observation of the environment.\n",
    "        \"\"\"\n",
    "        package_locations = [int(x) for row in self.packages for x in row]\n",
    "        delivery_locations = [int(x) for row in self.delivery_points for x in row]\n",
    "        obstacles = [int(x) for row in self.obstacles for x in row]\n",
    "        inventory = [int(x) for x in self.inventory]\n",
    "        return tuple(self.robot_pos + package_locations + delivery_locations + obstacles + inventory)\n",
    "\n",
    "def hash_state(env, state):\n",
    "    \"\"\"\n",
    "    Hashes the state tuple into a single integer for indexing.\n",
    "\n",
    "    Parameters:\n",
    "    - env (WarehouseEnv): Instance of the Warehouse environment.\n",
    "    - state (tuple): State tuple to be hashed.\n",
    "\n",
    "    Returns:\n",
    "    - hash_value (int): Hashed value of the state.\n",
    "    \"\"\"\n",
    "    hash_value = 0\n",
    "    for i, s in enumerate(state):\n",
    "        hash_value += s * (2 ** i)\n",
    "    return hash_value % env.q_table.shape[0]  # Ensure the hash value is within Q-table bounds\n",
    "\n",
    "\n",
    "def draw_env(screen, env):\n",
    "    \"\"\"\n",
    "    Draws the current state of the environment on the screen.\n",
    "\n",
    "    Parameters:\n",
    "    - screen (pygame.Surface): Pygame surface representing the screen.\n",
    "    - env (WarehouseEnv): Instance of the Warehouse environment.\n",
    "    \"\"\"\n",
    "    screen.fill((255, 255, 255))\n",
    "    cell_size = 50\n",
    "    grid_size = env.grid_size\n",
    "    robot_img = pygame.image.load(\"robot.png\").convert_alpha()\n",
    "    package_img = pygame.image.load(\"package.png\").convert_alpha()\n",
    "    delivery_img = pygame.image.load(\"delivery.png\").convert_alpha()\n",
    "    obstacle_img = pygame.image.load(\"warning.png\").convert_alpha()  # Load obstacle image\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            pygame.draw.rect(screen, (255, 255, 255), (j * cell_size, i * cell_size, cell_size, cell_size))\n",
    "            pygame.draw.rect(screen, (0, 0, 0), (j * cell_size, i * cell_size, cell_size, cell_size), 1)\n",
    "\n",
    "            if env.packages[i][j] == 1:\n",
    "                screen.blit(package_img, (j * cell_size, i * cell_size))\n",
    "            if env.delivery_points[i][j] == 1:\n",
    "                screen.blit(delivery_img, (j * cell_size, i * cell_size))\n",
    "            if env.obstacles[i][j] == 1:  # Draw obstacle if present\n",
    "                screen.blit(obstacle_img, (j * cell_size, i * cell_size))\n",
    "\n",
    "    robot_pos = env.robot_pos\n",
    "    screen.blit(robot_img, (robot_pos[1] * cell_size, robot_pos[0] * cell_size))\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = WarehouseEnv(grid_size=5, num_packages=3, num_delivery_points=3)\n",
    "\n",
    "    # Print the number of delivery points and packages\n",
    "    print(f\"Number of delivery points: {env.num_delivery_points}\")\n",
    "    print(f\"Number of packages: {env.num_packages}\")\n",
    "\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((env.grid_size * 50, env.grid_size * 50))\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    num_episodes = 500\n",
    "    max_steps_per_episode = 1000  # Define maximum steps per episode\n",
    "    epsilon = 0.1  # Define epsilon value for epsilon-greedy strategy\n",
    "    learning_rate = 0.1  # Define the learning rate\n",
    "    discount_factor = 0.99  # Define the discount factor\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        print(f\"Current Episode: {episode+1}\")  # Print current episode\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        steps = 0  # Initialize step count\n",
    "        exit_flag = False  # Flag to exit event handling loop\n",
    "        while not done and steps < max_steps_per_episode:  # Check maximum steps condition\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    exit_flag = True  # Set the exit flag to True\n",
    "                    break  # Exit the event handling loop\n",
    "            if exit_flag:\n",
    "                break  # Exit the episode loop if the exit flag is True\n",
    "            draw_env(screen, env)\n",
    "\n",
    "            current_state = env._get_observation()\n",
    "            hashed_state = hash_state(env, current_state)\n",
    "            if random.random() < epsilon:\n",
    "                action = env.action_space.sample()  # Choose a random action\n",
    "            else:\n",
    "                action = np.argmax(env.q_table[hashed_state])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            next_hashed_state = hash_state(env, next_state)\n",
    "            best_next_action = np.argmax(env.q_table[next_hashed_state])\n",
    "\n",
    "            # Update Q-table\n",
    "            env.q_table[hashed_state][action] += learning_rate * (\n",
    "                reward + discount_factor * env.q_table[next_hashed_state][best_next_action] - env.q_table[hashed_state][action])\n",
    "\n",
    "            clock.tick(10)\n",
    "            steps += 1  # Increment step count\n",
    "        print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0255c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
